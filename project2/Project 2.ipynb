{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDT4305 - Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import b64decode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "NORMALIZE_SCORES = False\n",
    "\n",
    "REDUCE_DATASET = False\n",
    "DATASET_FRACTION = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = sc.textFile('../data/yelp_top_reviewers_with_reviews.csv') \\\n",
    "    .zipWithIndex() \\\n",
    "    .filter(lambda x: x[1] > 0) \\\n",
    "    .map(lambda x: x[0].replace('\"', '').split('\\t')) \\\n",
    "    .map(lambda row: tuple(b64decode(row[i]).decode('utf8') if i == 3 else row[i] for i in range(len(row))))\n",
    "# \"review_id\",\"user_id\",\"business_id\",\"review_text\",\"review_date\"\n",
    "\n",
    "afinn = sc.textFile('../data/AFINN-111.txt') \\\n",
    "    .map(lambda x: x.split('\\t')) \\\n",
    "    .map(lambda row: (row[0], int(row[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('-lFvxYOmAuZMOelAs0dwgw',\n",
       " '---1lKK3aKOuomHnwAkAow',\n",
       " 'XJGMgs9Kh4kcgf8Oskiewg',\n",
       " 'I cant believe I have not Yelped this yet.  I think I only Yelp when I am hungry and then I only think food.  \\n\\nTheatre 7 is AMAZING!  Derek is one of the nicest guys in the community.  I Facebooked him and asked if I can use the space for TEDxYouth and he said yes.  He is very passionate about the independent film scene and the local Las Vegas Community.  You too can rent out the space for cool film events. \\n\\n@Misti we should have a YELP First Friday party here.  It would be really awesome! \\n\\nThey also did a Save the Huntridge build on a First Friday.\\n\\nDid I mention PolyGrind, zombies, blood gore, film festival right here in Vegas.  They take Red Carpet to a whole other level.  \\n\\nIt is also an art gallery space, improve class space, film networking space, and all around amazing place to be. \\n\\nSo if you are sick of watching romantic comedies at the megaplex grab a seat at Theatre 7.',\n",
       " '1347033511.000000')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('abandon', -2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I run a quick test to see that there are no duplicates in the AFINN set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert afinn.count() == afinn.map(lambda row: row[0]).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce data set (optional)\n",
    "Since the calculations include a quite massive join, I include an option to reduce the dataset, so that the functionality can be tested more efficiently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 4.29 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if REDUCE_DATASET:\n",
    "    count = reviews.count()\n",
    "    \n",
    "    reviews = reviews.zipWithIndex() \\\n",
    "        .filter(lambda row: row[1] < count * DATASET_FRACTION) \\\n",
    "        .map(lambda row: row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize review texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(review):\n",
    "    return re.sub('[^a-zA-Z ]+', '', review).lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = reviews.map(lambda row: ((row[0], row[1], row[2]), row[3])) \\\n",
    "    .flatMapValues(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start out by joining each word with its polarity score. This is a really heavy operation, so it will take a long time to run, but it is necessary. Note that I do a left outer join, keeping all words in each review, but setting a value of 0 for words not contained in AFINN. This is so that I later count the total number of words in each review, allowing for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NORMALIZE_SCORES:\n",
    "    word_polarity = tokenized \\\n",
    "        .map(lambda row: (row[1], row[0])) \\\n",
    "        .leftOuterJoin(afinn) \\\n",
    "        .map(lambda row: row[1]) \\\n",
    "        .map(lambda row: (row[0], 0 if row[1] is None else row[1]))\n",
    "else:\n",
    "    word_polarity = tokenized \\\n",
    "        .map(lambda row: (row[1], row[0])) \\\n",
    "        .join(afinn) \\\n",
    "        .map(lambda row: row[1]) \\\n",
    "        .map(lambda row: (row[0], 0 if row[1] is None else row[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the polarity of each word, I can sum to find the polarity of the review. I simultaneously count the total number of words, and divide by this in the end to find a normalized score. This is in order to avoid long reviews dominating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NORMALIZE_SCORES:\n",
    "    review_polarity = word_polarity.map(lambda row: (row[0], (row[1], 1))) \\\n",
    "        .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
    "        .map(lambda row: (row[0], row[1][0] / row[1][1]))\n",
    "else:\n",
    "        review_polarity = word_polarity \\\n",
    "            .reduceByKey(lambda x, y: (x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get most extreme reviews\n",
    "Looking at the highest ranking reviews is a great sanity check to see how well our system works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_review_ids = review_polarity.sortBy(lambda row: row[1], ascending=False).map(lambda row: row[0][0]).take(10)\n",
    "\n",
    "_ = list(map(lambda x: print(x[0] + 1, x[1], '\\n\\n'), \n",
    "         enumerate(reviews.filter(lambda row: row[0] in top_review_ids).map(lambda row: row[3]).collect())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_review_ids = review_polarity.sortBy(lambda row: row[1]).map(lambda row: row[0][0]).take(10)\n",
    "\n",
    "_ = list(map(lambda x: print(x[0] + 1, x[1], '\\n\\n'), \n",
    "         enumerate(reviews.filter(lambda row: row[0] in bottom_review_ids).map(lambda row: row[3]).collect())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.4 ms, sys: 19.7 ms, total: 79.1 ms\n",
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "business_ranking = review_polarity.map(lambda row: (row[0][2], row[1])) \\\n",
    "    .reduceByKey(lambda x, y: x + y) \\\n",
    "    .sortBy(lambda row: row[1], ascending=False) \\\n",
    "    .zipWithIndex().filter(lambda row: row[1] < k).map(lambda row: row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.36 ms, sys: 0 ns, total: 9.36 ms\n",
      "Wall time: 227 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('4JNXUYY8wbaaDmk3BPzlWw', 7306),\n",
       " ('RESDUcs7fIiihp38-d6_6g', 6461),\n",
       " ('igHYkXZMLAc9UdV5VnR_AA', 5784),\n",
       " ('k1QpHAkzKTrFYfk6u--VgQ', 5195),\n",
       " ('A5Rkh7UymKm0_Rxm9K2PJw', 5191),\n",
       " ('5LNZ67Yw9RD6nf4_UhXOjw', 5118),\n",
       " ('IMLrj2klosTFvPRLv56cng', 4975),\n",
       " ('PVTfzxu7of57zo1jZwEzkg', 4827),\n",
       " ('z6-reuC5BYf_Rth9gMBfgQ', 4816),\n",
       " ('7sPNbCx7vGAaH7SbNPZ6oA', 4813)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "business_ranking.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "business_ranking.zipWithIndex().filter(lambda row: row[1] < k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
